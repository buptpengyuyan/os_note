# 期末总学习

## os概述



## 计算机硬件概述

存储：主板，磁盘，内存，cpu缓存，cpu寄存器，cpu运算与控制单元

## boot和bootloader

开机先启动主板里的固定软件（固件）boot，特别小，主板自带，需保持最简化的功能

boot做设备检查等初始化操作

把控制权交给磁盘中的第一个程序：bootloader

## bootloader

是操作系统自带的一部分

用于将cpu的实模式转换到保护模式

然后检查os代码，磁盘读取os，移交控制权给os

## 实模式与保护模式

实模式很低级，cpu只能进行基本的有限的任务

保护模式很高级，cpu能进行高位操作，内存保护，进程管理等

为什么不一开始直接进入保护模式：因为要向后兼容，确保后来的计算机可以运行旧的软件os。

这整个从低到高的过程，其实也契合boot、loader、os这个过程，讲究一个慢慢来，一步一个脚印

## 进程

进程是程序的实例，是受限的

## 进程使用的虚拟内存

进程自己看来好像能使用所有的硬件资源，通过操作系统提供的虚拟内存机制获得了一个独立的、连续的地址空间。

假定其使用的空间像数据结构中的链表一样，高地址在上，低地址在下

那么这个空间可以分为很多段，从下到上可能是代码段，数据段，堆段，栈段

栈是从上往下伸展的，堆是从下往上伸展的

栈一般放函数调用栈

堆一般放各种初始化非初始化数据，代码数据

注：如果采用分段方式，那么映射到物理地址需要找到段表，通过pcb进程控制模块，其记录了这个信息

## 每个进程的pcb

进程控制块存储着该进程的各种信息，存放在内核空间

## 双模态

假定一个单核cpu同一时间只能处理一个进程，那么要么在内核态要么在用户态

用户态是受限的权力，内核态权力是无穷的

- 注：硬件通过2bit来表示当前的clp特权级别，有0-3个级别，但大多数os只是用0内核，3用户

什么什么
4个部分？

硬件主要实现：特权指令；内存保护；时间片中断，安全模式转换。

特权指令

##  进程内存管理/地址映射/内存保护

- 分段 

一个进程虚拟空间分出的每个段，与物理内存地址一一对应

映射的时候直接访问pcb说我这个段在哪，然后基础地址加偏移就找到了物理地址

- 分页

虚拟空间还是按照分段那样子管理数据，不过最高地址要加一个内核态代码

映射的时候重新把虚拟空间划分成多个特别小的块，这个块也叫页，然后映射到物理地址上

## 时间片中断

## 用户态到内核态

- 异常：进程在同步运行中发生了一个错误，进程抛出错误，内核接着处理异常

- 中断：进程自身运行好好的，操作系统突然发出异步指令叫他别做了，给我停下

    - 中断向量表：在实模式下使用，位置固定存储在cpu某个寄存器中
    - 中断描述符：在保护模式下使用，位置也存在某个cpu寄存器中，但是不固定

    中断屏蔽：不是所有中断都要发生，os可以mask一些中断，有些中断可以被mask。

    中断栈：存储在虚拟空间高地址的内核数据段中


- 系统调用：进程主动申请cpu启动内核态

## 内核态到用户态

- 创建新线程

- 切换不同线程，从一个时间片中断

- 用户态upcall？内核态使用用户态的接口

## x86的实例

- x86使用分段

- x86发生中断时

    - 硬件会做什么：
    - os会做什么

# 操作系统的接口与系统调用

## linux进程管理接口

-  fork（）

    - 当前进程执行fork，会创建一个新进程，新进程叫子进程，原来的进程叫父进程

    - 父子进程不共享地址空间，但是其中的数值一样

    - 父进程的fork返回子进程的pid，子进程的fork返回0

- exec（）

    - 将一个程序从磁盘中加载，把新数据覆盖掉当前进程的数据，但是保留pid，与部分环境

## linux的文件管理

- 文件描述表，打开文件表，i-node表

每个进程拥有一个文件描述表，在这个进程打开文件时，把该文件的文件描述符（一个整数）添加到该进程的文件描述表中。与此同时，也会在系统级的打开文件表创建一个文件项，存储信息，每个文件项还会单独对应一个i-node表项，其有更丰富的信息。

关闭一个文件，该进程的表会少一项，系统表对应的文件被索引数会减一，但i-node存储了文件的原数据，是不会动的。

## 线程

- 并发和并行：并行是真的两个线程在同时进程，但并发是通过调度，使得两个线程轮流进行，时间片短的话，看起来是一直在进行

- 线程概念：由进程‘分离’出来，是调度的最小单位；一个进程的不同线程共享该进程的数据，除了该进程的栈，因为栈是包含上下文的，每个线程拥有独立的上下文，拥有自己的栈。

- 生命周期：创建 --> 就绪 <--> 运行 --> 结束（死亡）   
线程在调度期间，需要等待其他线程结束之后才进行调度，那么在其最后一次运行，会进入（(等待)）挂起队列。之后进入就绪

## 线程控制块tcb

类似于进程控制块pcb

存储线程的上下文，寄存器值，元数据。

tcb和pcb都存放在进程的内核空间中，即虚拟空间的高地址。用户态线程的tcb放在进程的用户空间

## 内核态线程的实现

- 概念：全部都存储在内核空间，调度由os实现，只能采用os的时间片调度，可以被多核并行

- 创建

- 删除

- 切换

## 用户态线程的实现

- 概念：小部分数据tcb存储在内核空间，其他包括调度在内的都由用户自定义；本质上还是一个进程在单核上运行，只能并发不能并行。但上下文呢转换很快，因为没有系统调用，内存开销小。

# 地址翻译
目的：

- 保护
- 分享相同空间
- 灵活内存放置
- 稀疏地址？
- 高效查找
- 紧凑的翻译表
- 可移植

## 分段

根据虚拟空间的段选择词加偏移，去内核空间pcb中的段表找到这个段项（段项的大小一般也是32位），检查偏移是否在之间，检查是否有权限，通过则得到物理地址。

- x86实模式下

很狗吧奇怪，有一个16位的基地址，要乘以16（左移4位），再加上偏移，访问20位的物理地址。

- 保护模式下

之前讲每个进程翻译地址使用的段表叫LDT，局部描述符表，是每个进程自己拥有的，而GDT是系统在初始化时建立的全局描述符表，对所有进程可见。

## 分页

首先在32位操作系统中，所有的地址线都是32位，譬如虚拟地址，譬如段表项，譬如页表项

分页就是对虚拟空间划分为更细小的块（页），相比于块

地址线的划分其实类同与分段的翻译，都是第一部分是页表项数量用于查找页表项，第二部分是偏移量代表页大小

- 二级页表:将原来的20、12的虚拟地址划分变成了10、10、12，代表先从第一级页表查询第二级页表，再从第二级页表查询带偏移的物理地址

- 为什么二级目录要比一级页目录更节省空间

    首先考虑页的大小，2的12次方=4Kb，看似很大，其实进程的虚拟空间只有在真正使用的时候，os才会为他分配物理地址，称为懒加载，所以页大小无关紧要

    再考虑页表大小，采用一级目录，2的20次方个页表项，每个页表项为32位，需要4mb，太大了，使用二级页表，能使得第二级页表被使用到的时候再创建。

- 一级页表叫表目录pde，二级叫pte，前面20位表示地址信息，后面表示了其他信息

## mmu

os实现地址翻译很慢，需要用到mmu硬件。首先os读取页表，其次cpu读取页表，由mmu翻译，翻译完成后cpu去物理地址上取地址

## 缺页中断

当cpu/mmu进行地址翻译的时候，内存不存在页表对应的物理地址

发生情况：页表或页表项不存在，权限不足

## cow copy-on-write

基本思想：当两个东西需要用到同一个数据时，先共享这个数据的读操作，当其中一个东西想要写时，再创建新的副本（或一部分）。

在fork函数中，本来父子进程不应该使用相同的地址空间的，但为了节省空间，我们在进行写操作前允许他们能共享读取同一空间。

## 关于地址的一些问题

表目录前20crs存放着该表的地址。这个地址是物理的，如果他是虚拟的，那么你已经查表了还要查表，会是个无限循环问题。同理，许多在表查询中显示表地址的都是物理地址

大部分与页表段表无关联的地址，像是内核空间的地址都是虚拟地址，os是看不到物理地址的

内核向页表写入的地址是物理地址

## 自映射

将页目录（或跟高级的页表）中的一项指向页目录本身，然后试这个表项可以在外部通过虚拟地址调用，这叫自映射

# 缓存

平均访问时间 = 击中比率 * 击中时间 + 错失比率 * 错失时间

时间局部性与空间局部性

常见缓存：tlb缓存（cache of ptes）


## tlb缓存-translation lookaisde buffer

tlb概念：在mmu中缓存已经翻译好的虚拟与物理地址，具体是包含多个entry，每个entry包含一个物理地址，一个虚拟地址，一个许可

lookup：cpu首先根据虚拟地址在tlb中查找物理地址，有则命中；没有则继续查看页目录，查看页表，查看物理地址。完成翻译之后要再放入entry。

超页：一个虚拟地址对应一个太少了，我申请要一个更大的连续物理地址，这种一个虚拟地址对应多个物理地址叫超页。在连续的物理地址中根据虚拟地址的偏移量便可以对应其中的一个。

tlb一致性：如果一个虚拟地址到物理地址的映射因为系统的某些事件而改变了的话，tlb需将这一项舍弃或者更新。

## cache（cpu上的缓存）

假设cache结构为多个块（可能又叫行），主存结构也为多个块，但主存比cache多。

内存的数据如何放在cpucache上：

- 全相联映射：

    主存块随意放在cache中，

    cache块结构为：主存块直接标记 | 块内地址 （数据）

- 直接映射：
    
    将主存中的每个块对cache的块数取模直接放在cache上
    
    cache中的块地址结构为：主存块取模后的区标记 | cache块标记 | 块内地址 （数据）       
    注：假设块是行，使用行标记是因为，cache不是按行顺序存储的

- 组相联映射：

    结合前面两者的优点，组间是直接映射，组内是全相联映射

    直接映射中，主存区域是对cache的块数取模，现在是对cache的组数取模。可以这么理解，组是大体积的块，所以还是cache有多少块（组），主存每个区域就有多少个块。

    cache中块地址结构为：主存块取模后的区标记 | cache组号标记 | 块内地址

## cache replacement

当cache空间被占满之后，新加入的块如何代替久的块

- 随机
- fifo：先入先出算法
- lru算法-最近最少使用算法  
    基于假设：最近使用过的数据在未来被访问概率最高

## 在写入操作中保持缓存的一致性

- write-throught：将数据同时写入缓存与主存

    缺点：增加了访存次数

- write-back：在cache中命中，cache中数据修改完不会立即写入主存，只有当该cache块被替换的时候才写回主存

    缺点：增加了不一致的风险，要设置一个脏位表示cpu是否修改过这个值

## tlb与cache之间的联通

cpu是先通过tlb将虚拟地址转换到物理地址的，再进入cache，再进入memory主存的，由此可见tlb之后用的都是物理地址。

- cache使用的标记地址是物理的还是虚拟的：

    由上几节知，cache的块内地址分为主存标记和cache标记，由这个标记延伸出两种策略：
    - vipt：虚拟地址索引cache，物理地址标记
    - vivt：都用虚拟地址

## 进程的工作集

就是进程常驻在内存上的空间

## 页着色

cache的同一个地址可能被内核和用户在虚拟空间中命名为不同名称。这样在虚拟空间中就有两个地址映射到同一个，如果对一个修改，那另一个就是错的。

解决方式是页着色：强制使用别名的低地址位相同

# 需求分页

思想：一个程序只会使用到其百分之10的代码，所以只有当进程使用到某一文件时，才会把他加载到内存中，称为懒加载。

内存映射文件：思想与需求分页一致。目的是将硬盘中的文件映射到进程地址空间的技术，而不是用传统io独写操作，仿佛这些文件就是在内存上一样（这里我还不是很懂）

## 页面删除算法

除了刚刚的fifo，（lru没有）

- 时钟算法：近似lru

    将内存中的页按时钟排布，每次检查该页的使用位，
    
    如果该使用位为0，则表明这个页很久没用过了，可以被替换，然后跳转到下一个。

    如果是1，则说明这个页之前被使用过，之后还可能继续被使用，则clear重置使用位为0，然后跳转到下一个。

# 调度

当cpu一个核要处理多个任务的时候，要调度，分为抢占式调度和非抢占式调度，最常见的是时间片调度。

内核态线程调度是os完成的，用户态线程本质上还是一个线程，由用户线程库调用

- 评价指标：

    - 最小化线程们的响应时间
    - 最大化cpu的每秒操作数

## 计算题

等待时间：从任务到达开始，在等待队列的时间

完成时间：从任务到达时刻，到任务完成时间的总时间

记得使用甘特图。

## 调度策略

- fcfs ：first come first serve

- sjf ：shortest job first 最短时间优先，非抢占式

    可能会导致饥饿

- srtf ：shortest remaining time first 最短剩余时间，抢占式

- rr ：轮询

- sps ：strict priority schedule 严格优先级调度

- edf : 最早ddl算法

- mfq ：结合了之前算法，但都不是很优秀。
    
    采用多个优先级不同的队列，高优先级使用rr算法，低优先级使用fcfs，

    多队列之间的调度可以选用严格优先级调度，也可以给高优先级使用多的时间片，低优先级使用少的时间片。同时为了避免饥饿，当任务太久没获得时间片时提高其优先级。

- lottery s 彩票调度。给高优先级多的彩票，刮到谁就调度哪个，有随机性，我觉得不必多考虑这个

# 锁与时间变量

## 线程同步

在多线程、线程并发中，线程共享一段地址，但不能使他们同时执行同一段代码或者数据，不然会产生数据不一致等情况

概念：

- 使用原子性操作同步
- 互斥与临界区：保证只有一个线程在一段时间内访问一段代码或数据，表示该线程在这段时间与其他线程互斥；被访问的这段代码叫互斥区。

为什么使用锁：

虽然使用硬件的原子性操作能避免一段资源在一段时间内被两个线程使用，但毕竟依赖硬件层面，实现有点复杂，于是在软件层面上给资源引入锁（我目前是这么假设的，可能是错的），当一个线程在使用这段资源时这段资源上锁了，这个锁被这个线程获取了，当其他线程想要访问时只能等待这个线程释放这段资源的锁。

## 锁的实现

- 开关中断实现锁：  在单处理机上

    中断：对异步发生的中断请求响应，停止当前活动，启动请求

    关闭中断：线程获得锁的时候将中断响应关闭，使得线程在这段时间内使用玩这段资源后，才能进行上下文切换等操作。

    开启中断：可以响应外部的中断请求。中断的开关只能由os信任的代码执行。

- rmw操作 read modify write
  
    一系列原子操作，例如test&set ，compare&swap，swap等

    这里主要讲test and set spinlock自旋锁：

    测试锁的状态；尝试获取锁，如果可用则使用ts使其变为锁定状态；不可用的话，该线程进入自旋等待（存在盲等待，这是自旋的由来）

## 死锁

线程a持有着a锁，然后想要访问b资源寻求b锁，但是b资源b锁被b线程持有着，线程a只能等待线程b释放b锁，此时b线程如果想要寻求a锁，a锁又会被a线程持续占有而不放开。这样两个线程都陷入了相互等待，称为死锁

## 条件变量

一种机制，可用于解决死锁

解决方式：当一个线程寻求被锁资源而进去等待wait（&lock）时，会释放掉持有的所有锁，直到这个等待线程被唤醒，会重新拥有失去的锁。可以知道，进入wait之前和接受wait之后都持有锁，只是在中间暂时地释放锁。

条件变量体现在一个线程在索取资源，但在这个时候这个资源不满足某些条件（例如上锁，或者缓冲区不满或者缓冲区非空），会释放掉持有的锁。也就是说，条件变量的使用常常伴随着互斥锁。

经典问题是生产者与消费者。

条件变量具体的操作函数：

- wait（&lock）：释放持有锁，去等待队列。
- signal（）：唤醒一个线程
- broadcast（）：唤醒所有线程

## 信号量

一般使用条件变量+互斥锁来实现同步，但也可以用信号量，虽然信号量还是比不上前者。

信号量维护了一个计数器，表示当前可用资源数

如果一个线程从其中获取了资源，获取了一个锁，那么计数器减一；反之释放锁，计数器加一

计数器只能是非负数，如果是负数，新加入的线程将会被阻塞

对生产者消费者问题来说，要设置3个信号量。（具体的内容还没看）

操作：p操作使资源少一份--信号量减一，如果此时信号量为0则释放锁进入等待。v操作为释放锁，使资源多一份--信号量加一。

信号量除了多值，还有二元信号量，其实就是互斥锁。

其实两个条件变量加一个互斥锁就是，两个多值信号量加一个二元信号量。

这部分要会看代码。

## 小问题

加锁减锁是否要陷入内核态，队列锁是什么，中断处理可以使用自旋锁吗

# 读写者问题和死锁

- 问题描述：

    - 有一堆读线程，负责读取某个区域的，一堆写线程，负责给这个区域写入，写线程数量少于读线程数量。

    - 要求实现同步机制：写的时候不允许读，读的时候不允许写，但读的时候可以多个一起读
  
    - 要求实现写优先机制（或读优先机制）：一旦有一个写线程进入等待队列，那么写线程优先于等待读队列获取锁。

- 解决方案：
    
    - 使用一个互斥锁，两个条件变量，4个信号量（计数器）
    
    - 读写函数各分为三个阶段：获取锁（包含条件变量），运行，唤醒

    - 获取锁的时候都是使用条件变量，记得改变信号量或者叫计数器。

    - 运行之前要释放，运行之后要获取，read我能理解是因为要多个线程一起读，那write为啥也需要呢
    
    - 读线程需要sifnal唤醒一个写线程，写线程需要唤醒一个写线程或者全部读线程。

# 磁盘以及抽象

## 概念

内存是非持久化设备，二级存储器（除了主存储器内存之外，都叫二级存储器）是持久化设备

磁盘技术分类：硬盘磁盘，闪存固态

## 容量计算

存储容量 = 磁头数 * 柱面数 * 扇区数 * 扇区大小

（这里有点疑问的，为什么乘以扇区数之后还要乘以柱面数）

磁头数就是盘面数：一个硬盘有多个磁盘，一个磁盘两个扇面；柱面数就是一个盘面的磁道数，具体是半径不同的磁道的集合；扇区大小通常是512b。

题目：会给传输率，寻道时间，每分钟转速

要会算各种读取扇区数据的延时

## read生命周期

- 进程发起一个read系统调用
- os把进程放到等待队列
- os通知磁盘将数据放入内存
- 磁盘将数据放入内存
- 磁盘触发中断
- 中断使得os将内核数据放入用户地址空间中
- 线程进入准备队列
- 线程进入调度

## 文件系统

作用：命名；磁盘管理；文件保护；可靠性，持久性

## 

## 文件系统的工作流程

将文件路径在目录结构中换成一个文件号码

然后放到全局inode文件索引结构中

对应于磁盘中的多个块。

## 翻译文件地址流程

将文件路径转换成一个文件号码，作为一个索引去加载区块。然后os在内核pcb中创建一个文件描述符，返回一个handler句柄，方便以后进程使用这个文件。

## 目录结构

结果正常的‘/home/mnt/123djk’

将路径转换为文件号的步骤：从/根目录对应的inode中查找下一个路径对应的目录表项；然后进入下一路径目录表项，继续在这个目录表项对应的inode表中查找下一目录表项。以此循环。

以上文字好像有点问题，唯一肯定的是，根据当前文件去找当前的文件属性，然后这个属性里面存放着下一个文件的文件索引，循环利用索引去找属性。

## 如何用文件号映射到真正的物理数据块

- fat表：每个表项与磁盘中的每个块一一对应。

    假设一个文件需要用到3个块，那么这个文件号对应了第一个fat表项，这个fat表项还存放在下一个表项，如此循环找到3个表项，跟链表一样。

    fat存放在磁盘中的一个固定位置上。

    缺点很多

    32位地址，代表2的32次方个目录表项，所以限制是2的32次方个。

- ffs文件系统：

    ffs使用inode表（也叫inode array，元素是inode项，一个项对应一个文件）
    
    相比于fat将文件属性放在datablock中，ffs将属性直接放在inode项中
    
    每个inode项包含：元数据（文件属性）、直接索引（一般12个，用来直接索引一个block）、间接索引（用一个间接block存放多个32位地址，来索引多个datablock）

    优点：树结构快于链表、无论是大容量小容量都可以、固定结构；（感觉这个优点在放屁）

    ffs还有其他改进，只是考试不考，例如分了柱面组减少寻道时间

- ntfs： new tecnologic file system 微软文件系统
    
    也分目录结构MFT 以及具体的磁盘存放，但物理存放是以变长的extent为单位，目录结构是b+树结构

    目录和extent都用键值对的方式索引

    目录也很奇葩，表项是1kB，有时候能直接存储数据而不是索引；分常驻数据和非常驻

- VFS ：虚拟文件系统


## 小问题

如何在块组内部分配datablock？fat使用firstfit，填满之前的空隙，使得后面的趋于连续。

# 文件系统的可靠性

使用事务和raid冗余阵列

## 事务

概念和数据库一样，不多说了。开始一个事务之后，只有事务内任务都完成之后才会提交，否则会回滚。

原子性、一致性、隔离性、持久性

- redo logging实现：

    准备：将一个事务中所有操作写成一个log日志文件。

    提交：保证log写完之后，os运行提交。一旦事务被提交，他的影响也会被保留下来，即使系统崩溃。

    写回：此时开始将log中操作实现，将数据持久化到硬盘中，如果此时系统崩溃，那么os之后仍可以对照log进行写回然后重写重写，这就是redo名称由来。

- raid： 是一个将多个磁盘驱动器捆绑成一个逻辑单元存储。为了避免数据受单个磁盘的影响

    raid 0：将数据随机分散在多个磁盘中，一旦一个磁盘寄了，那么这个数据就寄了

    raid 1：将数据备份在多个磁盘中，蠢办法，浪费空间

    raid 5：使用带奇偶校验的raid 0

    这个raid估计不考，maybe也许。

## 






## final exercise课件中的疑点

- 为什么资源无限的时候不需要同步机制？
- 防止用户进程进入死锁原来不是os的任务
- 中断怎么就包括异常了

- 堆栈还不理解：
    - 栈存放着函数变量，返回地址，调用等各种栈信息，同一个进程的不同线程运行时有不同的操作，进入不同的函数，他们怎么能使用同一个栈呢
    - 一个进程的不同线程，他们中断时候的中断原因中断操作中断函数调用都不同，他们怎么可能共享一个内核态的中断栈呢
    - 使用c语言malloc语句创建一个堆后，堆在 

- 缺页中断的原因有哪些：权限不足，没有对应的物理映射
- fat不支持稀疏化文件表示。
- raid 技术还不是很了解
- 虚拟机包括后面几章还没有看

- 算冲突地址的时候，要将地址号先转换成块索引（消除地址偏移量），之后再进行模操作绝对值操作。
- 多线程调度中的亲和性：尽量将同一个线程调度在同一个核上，提交tlb和l1 cache的命中率。
- 磁盘的平均延迟时间指的是磁盘旋转耗时？

- 组相连映射中，我把组数跟路数搞反了，4路组映射不是说整个cache分为了4组，而是说每组有4个块，假设cache总共32个块，那么分成了8组，硬盘上的空间要对8取模的。


# 后面的章节
# 进程间交流inter-process-communication    IPC

进程们的特点：独立性，可合作

例子：web浏览器的主浏览器界面和其他选项卡是由不同进程合作的；chat等app是通过用户端进程与客户端进程进行通信的。

- pipe管道：

    - 一个进程的输出可以当作另一个进程的输入，好像有一个管道在其中。在linux用|表示单向管道，如果想双向，得设置两个

    - 使用fork函数使得父进程可以向
    - 上一个进程的输出会在内核空间中建立一个缓存区，然后传给下一个。

- 消息队列message queue：

    - 使得多个进程可以传入消息到一个队列进行通信，这个队列可以被读取

    - 这个消息可以是异步的，进程发出后不用等待。队列中的消息也可能有优先级。
    - 谈到邮箱是什么鬼

- 共享内存：

    - 共享内存区域允许两个或多个进程使用，当作通信

- rpc远程过程调用

# 
